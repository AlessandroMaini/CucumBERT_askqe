{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240cad7b",
   "metadata": {},
   "source": [
    "# AskQE Baseline Pipeline (Vanilla + NLI-Atomic)\n",
    "\n",
    "This notebook runs the full **baseline AskQE pipeline** end-to-end:\n",
    "\n",
    "1. **Fact Extraction** — extract atomic facts from source sentences (NLI pipeline only)\n",
    "2. **Question Generation** — Vanilla and Atomic QG via Qwen3-4B\n",
    "3. **Question Answering** — answer questions on source sentences\n",
    "4. **Add Questions to BT** — merge Q&A into back-translation files\n",
    "5. **QA on Back-Translations** — answer questions on perturbed back-translations\n",
    "6. **Evaluation** — SBERT, string-comparison, xCOMET, BT-Score, Pearson correlation, silhouette\n",
    "\n",
    "> **Runtime**: Requires **GPU** (Kaggle T4 / Colab T4 is sufficient). Total ~6–7 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/AlessandroMaini/CucumBERT_askqe.git\n",
    "!pip install -q -r CucumBERT_askqe/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99274d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGIN TO HUGGINGFACE\n",
    "import huggingface_hub\n",
    "huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"CucumBERT_askqe\")\n",
    "os.environ[\"GROQ_API_KEY\"] = \"\"  # ← paste your key here\n",
    "\n",
    "# Constants used throughout\n",
    "LANG_PAIRS  = {\"en-es\": \"es\", \"en-fr\": \"fr\"}\n",
    "PERTURBATIONS = [\"synonym\", \"alteration\", \"omission\", \"expansion_noimpact\"]\n",
    "PIPELINES = [\"vanilla\", \"atomic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553ff7e",
   "metadata": {},
   "source": [
    "## 1. Fact Extraction (NLI-Atomic pipeline only)\n",
    "Extract atomic facts from source sentences using Groq, then filter by NLI entailment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_SCRIPT = BASE / \"QG/fact-extraction/extract_facts_groq.py\"\n",
    "ENTAIL_SCRIPT  = BASE / \"QG/fact-extraction/entail_facts.py\"\n",
    "\n",
    "!python {EXTRACT_SCRIPT} --input_file \"data/processed/en-es.jsonl\"\n",
    "!python {ENTAIL_SCRIPT}  --input_file \"QG/atomic_facts.jsonl\" --threshold 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3099f4",
   "metadata": {},
   "source": [
    "## 2. Question Generation (Vanilla + Atomic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c403f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, str(BASE / \"QG/code\"))\n",
    "from qg_qwen3_4b import QuestionGenerator\n",
    "\n",
    "qg_engine = QuestionGenerator(model_id=\"Qwen/Qwen3-4B-Instruct-2507\")\n",
    "\n",
    "for variant in PIPELINES:\n",
    "    print(f\"\\n── QG: {variant} ──\")\n",
    "    qg_engine.generate_questions(\"data/processed/en-es.jsonl\", variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a29916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free QG model memory\n",
    "del qg_engine\n",
    "import torch; torch.cuda.empty_cache()\n",
    "\n",
    "cache_dir = BASE / \"QG/code/models--Qwen--Qwen3-4B-Instruct-2507\"\n",
    "if cache_dir.exists():\n",
    "    shutil.rmtree(cache_dir)\n",
    "    print(\"QG model cache deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf196688",
   "metadata": {},
   "source": [
    "## 3. Question Answering on Source Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3cca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, str(BASE / \"QA/code\"))\n",
    "from qa_qwen3_4b import QuestionAnswerer\n",
    "\n",
    "qa_engine = QuestionAnswerer(model_id=\"Qwen/Qwen3-4B-Instruct-2507\")\n",
    "\n",
    "for variant in PIPELINES:\n",
    "    print(f\"\\n── QA source: {variant} ──\")\n",
    "    qa_engine.answer_questions(\n",
    "        input_file=f\"QG/qwen3-4b/questions-{variant}.jsonl\",\n",
    "        pipeline_type=variant,\n",
    "        sentence_key=\"en\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c23a9d",
   "metadata": {},
   "source": [
    "## 4. Add Questions to Back-Translation Files\n",
    "Merge generated questions into BT files for both language pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_Q_SCRIPT = BASE / \"backtranslation/add_questions.py\"\n",
    "\n",
    "for variant in PIPELINES:\n",
    "    qg_file = f\"QG/qwen3-4b/questions-{variant}.jsonl\"\n",
    "    for lp in LANG_PAIRS:\n",
    "        for pert in PERTURBATIONS:\n",
    "            target  = f\"backtranslation/{lp}/bt-{pert}.jsonl\"\n",
    "            output  = f\"backtranslation/{lp}/bt-{pert}-{variant}.jsonl\"\n",
    "            print(f\"  {variant} | {lp} | {pert}\")\n",
    "            !python {ADD_Q_SCRIPT} --qg_file {qg_file} --target_file {target} --output_file {output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e78ad",
   "metadata": {},
   "source": [
    "## 5. QA on Back-Translated Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7d22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variant in PIPELINES:\n",
    "    for lp, lang in LANG_PAIRS.items():\n",
    "        for pert in PERTURBATIONS:\n",
    "            inp = f\"backtranslation/{lp}/bt-{pert}-{variant}.jsonl\"\n",
    "            print(f\"  {variant} | {lp} | {pert}\")\n",
    "            qa_engine.answer_questions(\n",
    "                input_file=inp,\n",
    "                pipeline_type=variant,\n",
    "                sentence_key=f\"bt_pert_{lang}\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f20f22",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AskQE metrics: SBERT + String comparison (F1, CHRF, BLEU)\n",
    "!python {BASE / \"evaluation/sbert/sbert.py\"} --model \"qwen3-4b\" --output_file \"evaluation/sbert/qwen3-4b.csv\"\n",
    "!python {BASE / \"evaluation/string-comparison/string_comparison.py\"} --model \"qwen3-4b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard MT metrics: xCOMET + BT-Score (BERTScore)\n",
    "!python {BASE / \"evaluation/xcomet/xcomet.py\"}\n",
    "!python {BASE / \"evaluation/bt-score/bt_score.py\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a768de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation + Silhouette score\n",
    "PEARSON_SCRIPT    = BASE / \"evaluation/pearson-correlation/compute_correlation.py\"\n",
    "SILHOUETTE_SCRIPT = BASE / \"evaluation/silhouette/silhouette_score.py\"\n",
    "\n",
    "for lp in LANG_PAIRS:\n",
    "    !python {PEARSON_SCRIPT}    --dataset {lp}\n",
    "    !python {SILHOUETTE_SCRIPT} --target-lang {lp}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
