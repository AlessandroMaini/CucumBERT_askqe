{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2396cd9b",
   "metadata": {},
   "source": [
    "# AskQE — Answerability-Check Extension Pipeline\n",
    "\n",
    "This notebook runs the full **answerability-check extension** of AskQE on Kaggle. It reproduces the pipeline end-to-end:\n",
    "\n",
    "1. **Answerability Check** — filter Vanilla questions with Longformer & ELECTRA\n",
    "2. **Question Answering** — answer filtered questions on source & back-translated sentences\n",
    "3. **Add Questions to BT** — merge filtered Q&A into back-translation files\n",
    "4. **QA on Back-Translations** — answer questions on perturbed back-translations\n",
    "5. **Evaluation** — compute SBERT and string-comparison (F1, CHRF, BLEU) metrics\n",
    "\n",
    "> **Runtime**: Requires **GPU** (Kaggle T4 is sufficient). Total ~3 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/AlessandroMaini/CucumBERT_askqe.git -b answerability-check\n",
    "%%capture\n",
    "!pip install -q -r CucumBERT_askqe/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c593b",
   "metadata": {},
   "source": [
    "## 1. Answerability Check — Filter Vanilla Questions\n",
    "\n",
    "Run the answerability-check filter on the Vanilla QG output using both models:\n",
    "- **Longformer** (`potsawee/longformer-large-4096-answerable-squad2`) — sequence classification\n",
    "- **ELECTRA** (`deepset/electra-base-squad2`) — extractive QA with null-score calibration\n",
    "\n",
    "Output: `questions-anscheck-longformer.jsonl` and `questions-anscheck-electra.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path('CucumBERT_askqe')\n",
    "\n",
    "# Run answerability check for both models\n",
    "!python {BASE / 'QG/answerability-check/answerability_check.py'} \\\n",
    "    --input_file QG/qwen3-4b/questions-vanilla.jsonl \\\n",
    "    --anscheck_type longformer\n",
    "\n",
    "!python {BASE / 'QG/answerability-check/answerability_check.py'} \\\n",
    "    --input_file QG/qwen3-4b/questions-vanilla.jsonl \\\n",
    "    --anscheck_type electra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77cdbef",
   "metadata": {},
   "source": [
    "## 2. Question Answering — Answer Filtered Questions on Source\n",
    "\n",
    "Load `Qwen/Qwen3-4B-Instruct-2507` once, then answer the filtered question sets.\n",
    "Each variant produces a QA output file used downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdef8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add QA module to path and load the model\n",
    "sys.path.insert(0, str(BASE / 'QA/code'))\n",
    "\n",
    "from qa_qwen3_4b import QuestionAnswerer\n",
    "qa_engine = QuestionAnswerer(model_id=\"Qwen/Qwen3-4B-Instruct-2507\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANTS = ['longformer', 'electra']\n",
    "SENTENCE_KEY = 'en'\n",
    "\n",
    "for variant in VARIANTS:\n",
    "    qa_engine.answer_questions(\n",
    "        input_file=f\"QG/qwen3-4b/questions-anscheck-{variant}.jsonl\",\n",
    "        pipeline_type=\"anscheck\",\n",
    "        sentence_key=SENTENCE_KEY,\n",
    "        check_variant=variant\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31174ca6",
   "metadata": {},
   "source": [
    "## 3. Merge Filtered Questions into Back-Translations\n",
    "\n",
    "For each anscheck variant × perturbation × language pair, merge the filtered questions\n",
    "into the existing back-translation files. This produces new BT files with the\n",
    "anscheck question sets attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANTS = ['anscheck-longformer', 'anscheck-electra']\n",
    "PERTURBATIONS = ['synonym', 'alteration', 'expansion_noimpact', 'omission']\n",
    "LANG_PAIRS = ['en-es', 'en-fr']\n",
    "\n",
    "for variant in VARIANTS:\n",
    "    qg_file = f\"QG/qwen3-4b/questions-{variant}.jsonl\"\n",
    "    for pert in PERTURBATIONS:\n",
    "        for lp in LANG_PAIRS:\n",
    "            target = f\"backtranslation/{lp}/bt-{pert}.jsonl\"\n",
    "            output = f\"backtranslation/{lp}/bt-{pert}-{variant}.jsonl\"\n",
    "            print(f\"  {variant} | {pert} | {lp}\")\n",
    "            !python {BASE / 'backtranslation/add_questions.py'} \\\n",
    "                --qg_file {qg_file} --target_file {target} --output_file {output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e62f90c",
   "metadata": {},
   "source": [
    "## 4. QA on Back-Translated Perturbations\n",
    "\n",
    "Answer the same filtered questions, this time on the **back-translated perturbed** sentences.\n",
    "The comparison between source answers (step 2) and BT answers (this step) is the core of AskQE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANTS = ['longformer', 'electra']\n",
    "PERTURBATIONS = ['synonym', 'alteration', 'expansion_noimpact', 'omission']\n",
    "\n",
    "# en→es\n",
    "for variant in VARIANTS:\n",
    "    for pert in PERTURBATIONS:\n",
    "        inp = f\"backtranslation/en-es/bt-{pert}-anscheck-{variant}.jsonl\"\n",
    "        print(f\"  {inp}\")\n",
    "        qa_engine.answer_questions(\n",
    "            input_file=inp, pipeline_type=\"anscheck\",\n",
    "            sentence_key='bt_pert_es', check_variant=variant)\n",
    "\n",
    "# en→fr\n",
    "for variant in VARIANTS:\n",
    "    for pert in PERTURBATIONS:\n",
    "        inp = f\"backtranslation/en-fr/bt-{pert}-anscheck-{variant}.jsonl\"\n",
    "        print(f\"  {inp}\")\n",
    "        qa_engine.answer_questions(\n",
    "            input_file=inp, pipeline_type=\"anscheck\",\n",
    "            sentence_key='bt_pert_fr', check_variant=variant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6652521e",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Compute AskQE answer-comparison metrics on the anscheck pipeline outputs:\n",
    "- **SBERT** — semantic similarity between source and BT answers\n",
    "- **String comparison** — F1, CHRF, BLEU token overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33554431",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {BASE / 'evaluation/sbert/sbert.py'} --model \"qwen3-4b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de9726",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {BASE / 'evaluation/string-comparison/string_comparison.py'} --model \"qwen3-4b\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
